{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EP.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"irmmOLPM2lRy","colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"status":"ok","timestamp":1591517027735,"user_tz":-120,"elapsed":65198,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"e63b3ac2-3158-451f-bf35-a9bd20e1745e"},"source":["import os\n","from getpass import getpass\n","user = getpass('GitHub user')\n","password = getpass('GitHub password')\n","os.environ['GITHUB_AUTH'] = user + ':' + password\n","!git clone https://$GITHUB_AUTH@github.com/kg192092/EP_JKS.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GitHub user··········\n","GitHub password··········\n","Cloning into 'EP_JKS'...\n","remote: Enumerating objects: 5, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 5205 (delta 0), reused 4 (delta 0), pack-reused 5200\u001b[K\n","Receiving objects: 100% (5205/5205), 601.45 MiB | 14.78 MiB/s, done.\n","Resolving deltas: 100% (7/7), done.\n","Checking out files: 100% (6173/6173), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RgpyOev6mWT3","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1591517697055,"user_tz":-120,"elapsed":1243,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"6849432a-038e-4089-dc9b-82d8f210408d"},"source":["import tensorflow as tf\n","\n","print(tf.version.VERSION)\n","\n","import numpy as np\n","np.version.version"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'1.17.5'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"0MMJ8RwAKnxo"},"source":["\n","import shutil\n","shutil.unpack_archive(\"/content/video.zip\", \"/content\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7OyyY9NHUAQ"},"source":["model_dir = '/content/drive/My Drive/Embedded_project/Training'\n","!ls -ltra '{model_dir}'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYCv1J0sMP-k","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1591517715019,"user_tz":-120,"elapsed":3963,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"5e5c721e-2f6c-442a-9261-93e41119364d"},"source":["!pip install tf_slim"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf_slim in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"txkJhC6QJCbk"},"source":["# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/kg192092/EP_JKS.git'\n","\n","# Number of training steps.\n","num_steps = 1000  # 200000\n","#num_steps = 100  # 200000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","\n","# model configs are from Model Zoo github: \n","# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models\n","MODELS_CONFIG = {\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\n","    'ssd_mobilenet_v1_quantized': {\n","        'model_name': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18',\n","        'pipeline_file': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync.config',\n","        'batch_size': 12\n","    },    \n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n","    'ssd_mobilenet_v2_quantized': {\n","        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n","        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 12\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","# Note: for Edge TPU, you have to:\n","# 1) start with a pretrained model from model zoo, such as above 4\n","# 2) Must be a quantized model, which reduces the model size significantly\n","selected_model = 'ssd_mobilenet_v2_quantized'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jn6NMknPJpTs","colab":{"base_uri":"https://localhost:8080/","height":83},"executionInfo":{"status":"ok","timestamp":1591517729976,"user_tz":-120,"elapsed":5216,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"aa991bf0-0c7d-4e73-a2c8-397d534c66e0"},"source":["import os\n","\n","%cd /content\n","\n","repo_dir_path = \"/content/EP_JKS/\"\n","\n","#!git clone {repo_url}\n","%cd {repo_dir_path}\n","\n","print('Pull it so that we have the latest code/data')\n","!git pull"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","/content/EP_JKS\n","Pull it so that we have the latest code/data\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NE9WPRKxKHzc"},"source":["pip uninstall tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wdJgURjM7UF"},"source":["!pip install tensorflow==1.15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHfUiW5WMBEE"},"source":["pip install --upgrade numpy==1.17.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVXKT4-3JyWX","colab":{"base_uri":"https://localhost:8080/","height":83},"executionInfo":{"status":"ok","timestamp":1591517755059,"user_tz":-120,"elapsed":18876,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"bab84e0e-9dd3-4959-9b88-3338415042e9"},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'models' already exists and is not an empty directory.\n","/content/models/research\n","object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yfl8k2YRL0CC","colab":{"base_uri":"https://localhost:8080/","height":66},"executionInfo":{"status":"ok","timestamp":1591456724990,"user_tz":-120,"elapsed":25772,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"cd76a927-53f2-4667-fde6-8e494c2669b8"},"source":["%cd /dataset/train/\n","# Generate `train.record`\n","!python /content/EP_JKS/code/generate_tfrecord.py --csv_input=/content/dataset/train/train.csv --output_path=/content/drive/My\\ Drive/Embedded_project/Training/train.record --img_path=/content/dataset/train/images --label_map /content/drive/My\\ Drive/Embedded_project/label_map.pbtxt\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/dataset/train/'\n","/content/models/research\n","Successfully created the TFRecords: /content/drive/My Drive/Embedded_project/Training/train.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8c3xeuQaifVX","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591456906022,"user_tz":-120,"elapsed":4214,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"57dc0d01-2333-413f-ddae-e7e390029823"},"source":["# Generate `test.record`\n","!python /content/EP_JKS/code/generate_tfrecord.py --csv_input=/content/dataset/test/test.csv --output_path=/content/drive/My\\ Drive/Embedded_project/Training/test.record --img_path=/content/dataset/test/images --label_map /content/drive/My\\ Drive/Embedded_project/label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Successfully created the TFRecords: /content/drive/My Drive/Embedded_project/Training/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2OfatN3CQ6wA"},"source":["test_record_fname = \"/content/drive/My\\ Drive/Embedded_project/Training/test.record\"\n","train_record_fname = \"/content/drive/My\\ Drive/Embedded_project/Training/train.record\"\n","label_map_pbtxt_fname =\"/content/label_map.pbtxt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xT8M3iCTQ6yB","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591517767968,"user_tz":-120,"elapsed":3707,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"cc616c04-a419-4d10-e520-ee28b0aad4f8"},"source":["%cd /content/dataset/test/\n","!cat test.csv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/dataset/test\n","filename,width,height,class,xmin,ymin,xmax,ymax\n","bottle_0.jpg,640,480,bottle,256,88,415,341\n","bottle_1.jpg,480,640,bottle,389,183,396,209\n","bottle_1.jpg,480,640,bottle,374,189,380,209\n","bottle_1.jpg,480,640,bottle,367,184,373,211\n","bottle_1.jpg,480,640,bottle,383,187,389,210\n","bottle_1.jpg,480,640,bottle,433,280,451,310\n","bottle_1.jpg,480,640,bottle,463,282,472,318\n","bottle_1.jpg,480,640,bottle,399,161,408,177\n","bottle_1.jpg,480,640,bottle,373,135,383,149\n","bottle_1.jpg,480,640,bottle,404,132,413,147\n","bottle_1.jpg,480,640,bottle,415,131,424,147\n","bottle_2.jpg,640,480,bottle,36,553,64,639\n","bottle_3.jpg,640,428,bottle,63,42,144,353\n","bottle_4.jpg,427,640,bottle,623,233,638,270\n","bottle_4.jpg,427,640,bottle,498,278,520,302\n","bottle_4.jpg,427,640,bottle,83,219,87,247\n","bottle_5.jpg,375,500,bottle,66,252,112,367\n","bottle_5.jpg,375,500,bottle,205,47,232,112\n","bottle_6.jpg,480,640,bottle,164,179,209,268\n","bottle_7.jpg,333,500,bottle,340,120,359,157\n","bottle_7.jpg,333,500,bottle,317,123,337,159\n","bottle_8.jpg,640,429,bottle,342,3,375,69\n","bottle_9.jpg,422,640,bottle,451,132,463,162\n","bottle_9.jpg,422,640,bottle,472,130,484,144\n","bottle_9.jpg,422,640,bottle,480,136,491,145\n","bottle_9.jpg,422,640,bottle,485,130,494,145\n","bottle_9.jpg,422,640,bottle,495,135,504,145\n","bottle_9.jpg,422,640,bottle,466,133,472,138\n","bottle_10.jpg,500,327,bottle,11,136,75,421\n","bottle_11.jpg,640,427,bottle,103,0,154,113\n","bottle_12.jpg,480,640,bottle,297,233,318,266\n","bottle_12.jpg,480,640,bottle,498,214,533,265\n","bottle_12.jpg,480,640,bottle,457,226,479,244\n","bottle_12.jpg,480,640,bottle,423,218,452,255\n","bottle_12.jpg,480,640,bottle,387,218,416,254\n","bottle_12.jpg,480,640,bottle,291,164,302,193\n","bottle_12.jpg,480,640,bottle,325,290,361,327\n","bottle_12.jpg,480,640,bottle,319,311,361,378\n","bottle_12.jpg,480,640,bottle,292,281,322,340\n","bottle_12.jpg,480,640,bottle,254,281,286,339\n","bottle_12.jpg,480,640,bottle,210,295,244,357\n","bottle_12.jpg,480,640,bottle,222,282,255,330\n","bottle_12.jpg,480,640,bottle,252,217,276,254\n","bottle_12.jpg,480,640,bottle,264,210,496,381\n","bottle_13.jpg,375,500,bottle,0,0,55,159\n","bottle_13.jpg,375,500,bottle,168,0,210,77\n","bottle_13.jpg,375,500,bottle,97,0,180,109\n","bottle_14.jpg,480,640,bottle,201,176,228,252\n","bottle_14.jpg,480,640,bottle,290,220,318,290\n","bottle_14.jpg,480,640,bottle,161,273,233,330\n","bottle_15.jpg,480,640,bottle,451,289,458,310\n","bottle_15.jpg,480,640,bottle,443,289,450,311\n","bottle_16.jpg,492,640,bottle,515,209,531,269\n","bottle_17.jpg,480,640,bottle,57,365,125,478\n","bottle_18.jpg,428,640,bottle,119,198,131,226\n","bottle_18.jpg,428,640,bottle,107,199,119,227\n","bottle_18.jpg,428,640,bottle,78,203,87,228\n","bottle_18.jpg,428,640,bottle,64,200,75,229\n","bottle_18.jpg,428,640,bottle,35,200,48,231\n","bottle_18.jpg,428,640,bottle,72,201,78,222\n","bottle_19.jpg,375,500,bottle,272,6,309,94\n","bottle_20.jpg,640,480,bottle,300,3,340,114\n","bottle_20.jpg,640,480,bottle,237,54,270,111\n","bottle_21.jpg,480,640,bottle,246,0,285,48\n","bottle_22.jpg,480,640,bottle,495,201,511,249\n","bottle_22.jpg,480,640,bottle,415,191,429,225\n","bottle_22.jpg,480,640,bottle,555,137,563,155\n","bottle_22.jpg,480,640,bottle,369,107,372,117\n","bottle_22.jpg,480,640,bottle,114,131,121,150\n","bottle_22.jpg,480,640,bottle,80,134,87,157\n","bottle_22.jpg,480,640,bottle,52,119,58,135\n","bottle_23.jpg,640,523,bottle,444,141,470,213\n","bottle_23.jpg,640,523,bottle,347,129,377,200\n","bottle_23.jpg,640,523,bottle,315,235,329,315\n","bottle_23.jpg,640,523,bottle,286,223,315,313\n","bottle_23.jpg,640,523,bottle,271,252,295,312\n","bottle_23.jpg,640,523,bottle,253,227,279,311\n","bottle_23.jpg,640,523,bottle,192,208,213,288\n","bottle_23.jpg,640,523,bottle,274,237,283,283\n","bottle_23.jpg,640,523,bottle,236,232,257,308\n","bottle_23.jpg,640,523,bottle,289,232,298,257\n","bottle_24.jpg,480,640,bottle,403,201,414,246\n","bottle_24.jpg,480,640,bottle,361,215,367,239\n","bottle_24.jpg,480,640,bottle,336,243,339,255\n","bottle_24.jpg,480,640,bottle,415,257,426,294\n","bottle_25.jpg,480,640,bottle,172,5,225,137\n","bottle_25.jpg,480,640,bottle,119,20,169,139\n","bottle_25.jpg,480,640,bottle,510,60,578,209\n","bottle_25.jpg,480,640,bottle,477,107,522,201\n","bottle_25.jpg,480,640,bottle,517,50,571,163\n","bottle_25.jpg,480,640,bottle,184,0,231,40\n","bottle_25.jpg,480,640,bottle,137,0,176,38\n","bottle_25.jpg,480,640,bottle,502,7,583,112\n","bottle_26.jpg,480,640,bottle,491,55,510,132\n","bottle_26.jpg,480,640,bottle,479,124,493,169\n","bottle_26.jpg,480,640,bottle,403,149,416,192\n","bottle_27.jpg,428,640,bottle,161,231,185,325\n","bottle_27.jpg,428,640,bottle,161,270,181,342\n","bottle_27.jpg,428,640,bottle,266,207,286,245\n","bottle_27.jpg,428,640,bottle,244,224,255,256\n","bottle_27.jpg,428,640,bottle,497,201,518,237\n","bottle_27.jpg,428,640,bottle,524,202,537,254\n","bottle_28.jpg,480,640,bottle,103,300,114,338\n","bottle_28.jpg,480,640,bottle,91,289,102,325\n","bottle_28.jpg,480,640,bottle,137,283,148,313\n","bottle_29.jpg,480,640,bottle,454,277,463,306\n","bottle_29.jpg,480,640,bottle,449,277,455,303\n","bottle_30.jpg,640,428,bottle,54,355,69,388\n","bottle_31.jpg,500,400,bottle,176,192,196,249\n","bottle_32.jpg,360,640,bottle,467,94,546,296\n","bottle_32.jpg,360,640,bottle,51,118,132,290\n","bottle_33.jpg,640,481,bottle,23,228,154,586\n","bottle_34.jpg,640,511,bottle,345,109,361,159\n","bottle_34.jpg,640,511,bottle,249,90,274,132\n","bottle_34.jpg,640,511,bottle,432,82,455,141\n","bottle_34.jpg,640,511,bottle,453,84,478,142\n","bottle_34.jpg,640,511,bottle,359,100,376,158\n","bottle_34.jpg,640,511,bottle,331,114,347,162\n","bottle_34.jpg,640,511,bottle,319,107,331,161\n","bottle_34.jpg,640,511,bottle,434,397,465,458\n","bottle_34.jpg,640,511,bottle,405,91,424,147\n","bottle_35.jpg,375,500,bottle,208,235,210,249\n","bottle_36.jpg,640,480,bottle,44,14,68,108\n","bottle_36.jpg,640,480,bottle,0,10,16,108\n","bottle_37.jpg,480,640,bottle,580,76,586,93\n","bottle_38.jpg,482,640,bottle,0,63,103,198\n","bottle_38.jpg,482,640,bottle,247,0,409,168\n","bottle_39.jpg,383,640,bottle,146,11,240,368\n","bottle_39.jpg,383,640,bottle,236,10,326,361\n","bottle_39.jpg,383,640,bottle,322,10,407,371\n","bottle_39.jpg,383,640,bottle,409,11,496,370\n","bottle_40.jpg,480,640,bottle,304,1,365,132\n","bottle_40.jpg,480,640,bottle,368,1,439,111\n","bottle_41.jpg,368,640,bottle,267,212,286,228\n","bottle_42.jpg,426,640,bottle,383,48,423,119\n","bottle_42.jpg,426,640,bottle,359,48,394,93\n","bottle_42.jpg,426,640,bottle,92,0,146,57\n","bottle_42.jpg,426,640,bottle,214,8,242,47\n","bottle_43.jpg,480,640,bottle,188,287,199,320\n","bottle_44.jpg,427,640,bottle,366,149,406,194\n","bottle_45.jpg,427,640,bottle,591,359,609,379\n","bottle_45.jpg,427,640,bottle,572,356,617,420\n","bottle_46.jpg,640,427,bottle,184,530,255,629\n","bottle_47.jpg,640,491,bottle,307,300,336,433\n","bottle_47.jpg,640,491,bottle,259,282,299,442\n","bottle_47.jpg,640,491,bottle,204,274,251,446\n","bottle_47.jpg,640,491,bottle,151,276,192,461\n","bottle_47.jpg,640,491,bottle,124,329,151,456\n","bottle_47.jpg,640,491,bottle,87,273,137,470\n","bottle_48.jpg,427,640,bottle,365,237,396,353\n","bottle_48.jpg,427,640,bottle,402,230,427,351\n","bottle_48.jpg,427,640,bottle,419,228,435,331\n","bottle_48.jpg,427,640,bottle,396,227,412,337\n","bottle_48.jpg,427,640,bottle,238,234,260,282\n","bottle_49.jpg,427,640,bottle,533,50,607,201\n","bottle_49.jpg,427,640,bottle,496,94,544,174\n","bottle_50.jpg,426,640,bottle,212,66,228,123\n","bottle_50.jpg,426,640,bottle,466,268,492,326\n","bottle_50.jpg,426,640,bottle,45,271,68,348\n","bottle_51.jpg,480,640,bottle,103,129,131,204\n","bottle_51.jpg,480,640,bottle,96,131,113,194\n","bottle_52.jpg,542,640,bottle,504,312,537,379\n","bottle_53.jpg,640,480,bottle,201,331,209,368\n","bottle_54.jpg,425,640,bottle,290,242,305,290\n","bottle_55.jpg,612,612,bottle,454,406,490,473\n","bottle_55.jpg,612,612,bottle,311,500,364,595\n","bottle_55.jpg,612,612,bottle,411,384,450,482\n","bottle_55.jpg,612,612,bottle,364,488,405,593\n","bottle_56.jpg,612,612,bottle,545,221,554,235\n","bottle_56.jpg,612,612,bottle,555,221,566,235\n","bottle_56.jpg,612,612,bottle,568,221,577,235\n","bottle_56.jpg,612,612,bottle,578,182,585,206\n","bottle_56.jpg,612,612,bottle,255,352,277,410\n","bottle_56.jpg,612,612,bottle,590,221,601,235\n","bottle_56.jpg,612,612,bottle,153,218,164,264\n","bottle_56.jpg,612,612,bottle,203,230,210,258\n","bottle_56.jpg,612,612,bottle,579,222,589,235\n","bottle_57.jpg,480,640,bottle,94,288,107,323\n","bottle_57.jpg,480,640,bottle,386,219,399,258\n","bottle_57.jpg,480,640,bottle,399,218,412,249\n","bottle_58.jpg,478,640,bottle,144,115,175,176\n","bottle_58.jpg,478,640,bottle,231,155,237,171\n","bottle_59.jpg,480,640,bottle,290,267,305,300\n","bottle_60.jpg,480,640,bottle,141,374,200,471\n","bottle_61.jpg,480,640,bottle,497,171,628,386\n","bottle_62.jpg,507,640,bottle,452,1,610,55\n","bottle_63.jpg,480,640,bottle,450,237,463,262\n","bottle_63.jpg,480,640,bottle,467,232,478,275\n","bottle_64.jpg,375,500,bottle,95,0,170,139\n","bottle_64.jpg,375,500,bottle,177,0,236,121\n","bottle_65.jpg,425,640,bottle,0,318,19,383\n","bottle_65.jpg,425,640,bottle,188,210,202,271\n","bottle_65.jpg,425,640,bottle,1,365,27,423\n","bottle_66.jpg,364,640,bottle,81,22,92,60\n","bottle_67.jpg,612,612,bottle,290,0,419,72\n","bottle_68.jpg,480,640,bottle,301,99,316,141\n","bottle_68.jpg,480,640,bottle,317,101,331,132\n","bottle_68.jpg,480,640,bottle,351,97,390,151\n","bottle_69.jpg,612,612,bottle,535,365,586,474\n","bottle_69.jpg,612,612,bottle,356,221,366,251\n","bottle_69.jpg,612,612,bottle,366,221,376,254\n","bottle_69.jpg,612,612,bottle,581,367,611,479\n","bottle_70.jpg,480,640,bottle,40,286,54,335\n","bottle_71.jpg,640,480,bottle,256,365,269,393\n","bottle_71.jpg,640,480,bottle,246,364,258,393\n","bottle_71.jpg,640,480,bottle,268,364,280,395\n","bottle_71.jpg,640,480,bottle,229,364,245,392\n","bottle_72.jpg,480,640,bottle,126,215,156,251\n","bottle_73.jpg,640,427,bottle,161,184,183,241\n","bottle_73.jpg,640,427,bottle,144,165,162,241\n","bottle_73.jpg,640,427,bottle,178,173,199,238\n","bottle_73.jpg,640,427,bottle,108,162,138,243\n","bottle_73.jpg,640,427,bottle,131,163,145,236\n","bottle_73.jpg,640,427,bottle,80,153,108,197\n","bottle_73.jpg,640,427,bottle,154,152,171,164\n","bottle_73.jpg,640,427,bottle,160,165,169,199\n","bottle_74.jpg,317,400,bottle,248,140,274,164\n","bottle_74.jpg,317,400,bottle,267,145,275,167\n","bottle_75.jpg,346,640,bottle,337,126,343,144\n","bottle_75.jpg,346,640,bottle,356,125,360,140\n","bottle_75.jpg,346,640,bottle,330,122,338,144\n","bottle_76.jpg,568,640,bottle,359,319,378,354\n","bottle_76.jpg,568,640,bottle,333,329,352,364\n","bottle_76.jpg,568,640,bottle,258,352,297,413\n","bottle_76.jpg,568,640,bottle,234,342,256,377\n","bottle_76.jpg,568,640,bottle,344,326,362,360\n","bottle_77.jpg,426,640,bottle,272,210,276,229\n","bottle_77.jpg,426,640,bottle,261,206,268,229\n","bottle_77.jpg,426,640,bottle,279,213,283,228\n","bottle_77.jpg,426,640,bottle,299,209,308,228\n","bottle_78.jpg,480,640,bottle,428,314,451,367\n","bottle_78.jpg,480,640,bottle,250,227,267,264\n","bottle_78.jpg,480,640,bottle,226,204,240,257\n","bottle_79.jpg,612,612,bottle,126,204,135,236\n","bottle_79.jpg,612,612,bottle,169,228,182,255\n","bottle_80.jpg,479,640,bottle,510,324,524,366\n","bottle_80.jpg,479,640,bottle,550,346,558,398\n","bottle_80.jpg,479,640,bottle,541,354,551,389\n","bottle_80.jpg,479,640,bottle,521,332,532,375\n","bottle_80.jpg,479,640,bottle,544,410,554,455\n","bottle_80.jpg,479,640,bottle,535,424,542,443\n","bottle_80.jpg,479,640,bottle,533,337,547,384\n","bottle_81.jpg,480,640,bottle,16,297,41,358\n","bottle_82.jpg,427,640,bottle,140,256,167,275\n","bottle_83.jpg,640,480,bottle,384,350,419,423\n","bottle_83.jpg,640,480,bottle,258,520,322,619\n","bottle_84.jpg,425,640,bottle,384,9,433,72\n","bottle_85.jpg,428,640,bottle,60,2,177,200\n","bottle_85.jpg,428,640,bottle,295,1,440,363\n","bottle_85.jpg,428,640,bottle,137,1,288,231\n","bottle_86.jpg,480,640,bottle,453,2,540,153\n","bottle_86.jpg,480,640,bottle,248,0,329,154\n","bottle_86.jpg,480,640,bottle,541,3,638,195\n","bottle_86.jpg,480,640,bottle,409,0,468,144\n","bottle_86.jpg,480,640,bottle,365,10,416,139\n","bottle_86.jpg,480,640,bottle,332,2,413,117\n","bottle_86.jpg,480,640,bottle,577,79,639,228\n","bottle_87.jpg,480,640,bottle,549,16,560,75\n","bottle_87.jpg,480,640,bottle,558,26,568,75\n","bottle_88.jpg,480,640,bottle,535,184,551,227\n","bottle_89.jpg,427,640,bottle,115,285,129,330\n","bottle_90.jpg,426,640,bottle,229,251,250,317\n","bottle_90.jpg,426,640,bottle,391,214,408,244\n","bottle_90.jpg,426,640,bottle,357,214,369,241\n","bottle_90.jpg,426,640,bottle,221,250,234,314\n","bottle_90.jpg,426,640,bottle,385,138,398,175\n","bottle_91.jpg,480,640,bottle,101,346,133,408\n","bottle_91.jpg,480,640,bottle,183,414,230,478\n","bottle_91.jpg,480,640,bottle,100,392,149,479\n","bottle_92.jpg,480,640,bottle,567,204,594,245\n","bottle_93.jpg,471,640,bottle,69,359,87,383\n","bottle_94.jpg,640,450,bottle,204,524,233,564\n","bottle_94.jpg,640,450,bottle,183,500,216,533\n","bottle_94.jpg,640,450,bottle,147,547,172,573\n","bottle_94.jpg,640,450,bottle,210,511,229,529\n","bottle_94.jpg,640,450,bottle,145,552,195,576\n","bottle_94.jpg,640,450,bottle,182,567,228,582\n","bottle_94.jpg,640,450,bottle,179,566,220,578\n","bottle_94.jpg,640,450,bottle,187,523,212,554\n","bottle_95.jpg,506,640,bottle,18,122,112,273\n","bottle_96.jpg,359,640,bottle,88,245,115,303\n","bottle_97.jpg,480,640,bottle,341,3,400,203\n","bottle_97.jpg,480,640,bottle,222,0,305,137\n","bottle_97.jpg,480,640,bottle,245,103,299,205\n","bottle_98.jpg,480,640,bottle,362,298,384,350\n","bottle_98.jpg,480,640,bottle,411,310,423,342\n","bottle_99.jpg,640,460,bottle,350,159,369,214\n","bottle_99.jpg,640,460,bottle,341,317,370,378\n","bottle_99.jpg,640,460,bottle,369,318,391,374\n","bottle_99.jpg,640,460,bottle,379,233,410,296\n","bottle_99.jpg,640,460,bottle,381,86,407,135\n","bottle_99.jpg,640,460,bottle,351,84,370,131\n","IMG_20200603_130329.jpg,300,300,laptop,56,66,239,254\n","IMG_20200603_130404.jpg,300,300,laptop,150,34,237,136\n","IMG_20200603_130454.jpg,300,300,bottle,102,38,130,117\n","IMG_20200603_130454.jpg,300,300,laptop,143,35,217,118\n","IMG_20200603_130642.jpg,300,300,bottle,116,93,140,160\n","IMG_20200603_130642.jpg,300,300,laptop,143,85,211,159\n","IMG_20200603_130749.jpg,300,300,bottle,189,96,239,275\n","IMG_20200603_130749.jpg,300,300,bottle,125,29,164,202\n","IMG_20200603_131019.jpg,300,300,bin,96,86,174,215\n","IMG_20200603_131045.jpg,300,300,bin,107,29,252,280\n","IMG_20200603_131107.jpg,300,300,bin,25,51,171,278\n","IMG_20200603_131107.jpg,300,300,bin,167,73,272,243\n","IMG_20200603_131128.jpg,300,300,bin,147,49,203,155\n","IMG_20200603_131128.jpg,300,300,bin,217,102,294,225\n","IMG_20200603_131128.jpg,300,300,laptop,24,114,160,268\n","IMG_20200603_131155.jpg,300,300,laptop,115,78,273,276\n","IMG_20200603_131155.jpg,300,300,bin,41,21,126,155\n","IMG_20200603_131237.jpg,300,300,bin,18,82,112,252\n","IMG_20200603_131237.jpg,300,300,bin,111,92,172,194\n","IMG_20200603_131237.jpg,300,300,laptop,156,124,294,292\n","IMG_20200603_131306.jpg,300,300,bottle,127,146,148,212\n","IMG_20200603_131306.jpg,300,300,bottle,236,138,284,243\n","IMG_20200603_131306.jpg,300,300,bin,78,46,139,161\n","IMG_20200603_131306.jpg,300,300,bin,139,56,185,137\n","IMG_20200603_131306.jpg,300,300,laptop,159,90,265,216\n","IMG_20200603_131350.jpg,300,300,bottle,117,125,158,249\n","IMG_20200603_131350.jpg,300,300,bin,56,41,138,183\n","IMG_20200603_131403.jpg,300,300,bin,28,48,117,202\n","IMG_20200603_131403.jpg,300,300,bottle,104,187,135,268\n","IMG_20200603_131403.jpg,300,300,bottle,130,176,187,284\n","IMG_20200603_131425.jpg,300,300,bin,191,80,255,185\n","IMG_20200603_131425.jpg,300,300,bin,1,78,102,242\n","IMG_20200603_131502.jpg,300,300,bottle,214,124,259,286\n","IMG_20200603_131502.jpg,300,300,bin,59,78,159,251\n","IMG_20200603_131541.jpg,300,300,laptop,1,108,118,249\n","IMG_20200603_131541.jpg,300,300,bin,90,59,152,176\n","IMG_20200603_131541.jpg,300,300,bin,235,78,300,180\n","IMG_20200603_131541.jpg,300,300,bottle,185,96,213,192\n","IMG_20200603_131541.jpg,300,300,bottle,145,136,166,203\n","IMG_20200603_131615.jpg,300,300,laptop,24,142,125,268\n","IMG_20200603_131615.jpg,300,300,bin,120,118,178,217\n","IMG_20200603_131615.jpg,300,300,bin,207,93,267,234\n","IMG_20200603_131633.jpg,300,300,bin,100,87,174,202\n","IMG_20200603_131633.jpg,300,300,bin,189,66,262,258\n","IMG_20200603_131645.jpg,300,300,bin,99,107,176,223\n","IMG_20200603_131645.jpg,300,300,bin,178,58,278,249\n","IMG_20200603_131657.jpg,300,300,bin,80,95,145,201\n","IMG_20200603_131657.jpg,300,300,bin,173,57,260,215\n","IMG_20200603_131657.jpg,300,300,bottle,144,159,193,300\n","IMG_20200603_131657.jpg,300,300,bottle,119,186,152,272\n","IMG_20200603_131714.jpg,300,300,bin,44,49,135,217\n","IMG_20200603_131714.jpg,300,300,bin,157,56,222,166\n","IMG_20200603_131714.jpg,300,300,bottle,156,162,196,300\n","IMG_20200603_131842.jpg,300,300,bin,5,42,98,196\n","IMG_20200603_131842.jpg,300,300,bin,111,45,167,143\n","IMG_20200603_131842.jpg,300,300,bottle,235,107,287,222\n","IMG_20200603_131907.jpg,300,300,bottle,60,62,89,146\n","IMG_20200603_131907.jpg,300,300,bin,162,103,236,224\n","IMG_20200603_131907.jpg,300,300,bin,210,33,256,138\n","IMG_20200603_131940.jpg,300,300,bin,1,30,77,225\n","IMG_20200603_131940.jpg,300,300,bin,72,33,155,168\n","IMG_20200603_131940.jpg,300,300,laptop,148,45,291,213\n","IMG_20200603_131958.jpg,300,300,bottle,16,93,37,137\n","IMG_20200603_131958.jpg,300,300,laptop,84,108,182,222\n","IMG_20200603_131958.jpg,300,300,bin,2,141,88,287\n","IMG_20200603_131958.jpg,300,300,bin,203,71,288,234\n","IMG_20200603_132026.jpg,300,300,bin,96,24,221,283\n","IMG_20200603_132037.jpg,300,300,bottle,26,32,63,137\n","IMG_20200603_132037.jpg,300,300,bottle,189,47,204,98\n","IMG_20200603_132037.jpg,300,300,bin,100,113,210,288\n","IMG_20200603_132120.jpg,300,300,bin,18,132,119,295\n","IMG_20200603_132120.jpg,300,300,bottle,67,65,95,131\n","IMG_20200603_132120.jpg,300,300,bottle,224,82,240,140\n","IMG_20200603_132145.jpg,300,300,bin,24,70,92,197\n","IMG_20200603_132145.jpg,300,300,bin,99,118,171,246\n","IMG_20200603_132145.jpg,300,300,bottle,177,157,210,286\n","IMG_20200603_132145.jpg,300,300,bottle,189,66,202,110\n","IMG_20200603_132159.jpg,300,300,bottle,144,121,170,223\n","IMG_20200603_132159.jpg,300,300,bin,1,27,128,249\n","IMG_20200603_132159.jpg,300,300,bin,181,56,294,229\n","IMG_20200603_132215.jpg,300,300,laptop,1,115,114,256\n","IMG_20200603_132215.jpg,300,300,bottle,130,77,151,169\n","IMG_20200603_132215.jpg,300,300,bottle,147,81,157,131\n","IMG_20200603_132215.jpg,300,300,bin,163,50,207,129\n","IMG_20200603_132215.jpg,300,300,bin,86,35,138,143\n","IMG_20200603_155518.jpg,300,300,bin,145,175,211,282\n","IMG_20200603_155642.jpg,300,300,bin,123,130,153,180\n","laptop_0.jpg,640,446,laptop,123,468,161,487\n","laptop_1.jpg,480,640,laptop,249,50,623,326\n","laptop_1.jpg,480,640,laptop,152,50,622,361\n","laptop_2.jpg,480,640,laptop,313,267,468,453\n","laptop_2.jpg,480,640,laptop,139,175,218,270\n","laptop_3.jpg,427,640,laptop,608,200,639,264\n","laptop_4.jpg,375,500,laptop,278,0,499,369\n","laptop_5.jpg,375,500,laptop,17,176,184,287\n","laptop_6.jpg,375,500,laptop,128,108,350,285\n","laptop_6.jpg,375,500,laptop,82,115,256,318\n","laptop_6.jpg,375,500,laptop,2,128,243,357\n","laptop_7.jpg,480,640,laptop,258,397,423,479\n","laptop_7.jpg,480,640,laptop,115,276,269,371\n","laptop_7.jpg,480,640,laptop,0,185,37,219\n","laptop_7.jpg,480,640,laptop,0,257,61,294\n","laptop_7.jpg,480,640,laptop,83,122,114,144\n","laptop_7.jpg,480,640,laptop,506,240,627,286\n","laptop_7.jpg,480,640,laptop,564,187,632,202\n","laptop_7.jpg,480,640,laptop,63,96,82,112\n","laptop_7.jpg,480,640,laptop,0,223,48,241\n","laptop_8.jpg,375,500,laptop,306,158,440,286\n","laptop_9.jpg,375,500,laptop,251,171,388,255\n","laptop_9.jpg,375,500,laptop,125,161,213,220\n","laptop_9.jpg,375,500,laptop,160,121,212,174\n","laptop_9.jpg,375,500,laptop,201,120,252,158\n","laptop_9.jpg,375,500,laptop,196,146,214,180\n","laptop_9.jpg,375,500,laptop,244,122,294,168\n","laptop_10.jpg,480,640,laptop,208,188,427,462\n","laptop_10.jpg,480,640,laptop,385,90,615,130\n","laptop_10.jpg,480,640,laptop,160,11,372,124\n","laptop_10.jpg,480,640,laptop,375,126,612,178\n","laptop_10.jpg,480,640,laptop,374,147,591,200\n","laptop_10.jpg,480,640,laptop,163,53,376,150\n","laptop_10.jpg,480,640,laptop,158,116,341,170\n","laptop_10.jpg,480,640,laptop,1,25,179,119\n","laptop_10.jpg,480,640,laptop,1,43,183,140\n","laptop_10.jpg,480,640,laptop,0,90,166,162\n","laptop_10.jpg,480,640,laptop,154,140,351,190\n","laptop_10.jpg,480,640,laptop,163,151,356,199\n","laptop_10.jpg,480,640,laptop,0,0,622,265\n","laptop_10.jpg,480,640,laptop,370,167,587,343\n","laptop_11.jpg,500,400,laptop,221,195,312,268\n","laptop_12.jpg,480,640,laptop,308,61,576,334\n","laptop_12.jpg,480,640,laptop,95,186,302,399\n","laptop_13.jpg,427,640,laptop,298,75,639,419\n","laptop_14.jpg,364,500,laptop,0,312,178,363\n","laptop_15.jpg,480,640,laptop,0,0,605,176\n","laptop_16.jpg,480,640,laptop,517,363,605,438\n","laptop_17.jpg,480,640,laptop,506,326,603,383\n","laptop_17.jpg,480,640,laptop,441,226,489,259\n","laptop_17.jpg,480,640,laptop,458,211,494,245\n","laptop_17.jpg,480,640,laptop,493,212,523,252\n","laptop_17.jpg,480,640,laptop,499,223,521,267\n","laptop_17.jpg,480,640,laptop,0,244,54,305\n","laptop_17.jpg,480,640,laptop,93,220,109,252\n","laptop_17.jpg,480,640,laptop,143,192,158,208\n","laptop_17.jpg,480,640,laptop,220,194,244,222\n","laptop_18.jpg,480,640,laptop,236,135,380,271\n","laptop_19.jpg,338,640,laptop,110,83,283,279\n","laptop_20.jpg,479,640,laptop,340,152,617,383\n","laptop_20.jpg,479,640,laptop,14,144,125,220\n","laptop_21.jpg,426,640,laptop,185,30,374,130\n","laptop_22.jpg,390,640,laptop,43,188,133,290\n","laptop_23.jpg,482,640,laptop,60,5,528,460\n","laptop_24.jpg,427,640,laptop,188,0,447,135\n","laptop_25.jpg,480,640,laptop,59,289,263,418\n","laptop_26.jpg,333,500,laptop,93,233,148,246\n","laptop_27.jpg,374,640,laptop,48,158,194,311\n","laptop_28.jpg,480,640,laptop,61,55,403,336\n","laptop_29.jpg,480,640,laptop,0,268,120,392\n","laptop_30.jpg,480,640,laptop,512,66,637,173\n","laptop_31.jpg,331,500,laptop,75,28,274,161\n","laptop_32.jpg,480,640,laptop,65,225,308,463\n","laptop_32.jpg,480,640,laptop,386,206,628,460\n","laptop_33.jpg,480,640,laptop,2,168,59,188\n","laptop_34.jpg,480,640,laptop,457,194,570,297\n","laptop_35.jpg,425,640,laptop,444,346,562,375\n","laptop_36.jpg,480,640,laptop,331,260,430,323\n","laptop_37.jpg,640,478,laptop,99,35,447,427\n","laptop_38.jpg,480,640,laptop,328,430,452,479\n","laptop_39.jpg,640,480,laptop,74,248,444,550\n","laptop_40.jpg,346,640,laptop,123,159,207,222\n","laptop_41.jpg,480,640,laptop,0,2,281,406\n","laptop_42.jpg,480,640,laptop,73,189,182,221\n","laptop_43.jpg,480,640,laptop,354,249,563,466\n","laptop_44.jpg,640,457,laptop,185,74,429,283\n","laptop_45.jpg,478,640,laptop,111,202,257,324\n","laptop_46.jpg,480,640,laptop,569,256,639,316\n","laptop_47.jpg,640,640,laptop,0,424,639,511\n","laptop_48.jpg,333,500,laptop,163,56,284,99\n","laptop_49.jpg,333,500,laptop,271,153,496,317\n","laptop_50.jpg,480,640,laptop,344,175,441,247\n","laptop_50.jpg,480,640,laptop,409,200,482,220\n","laptop_50.jpg,480,640,laptop,441,137,504,205\n","laptop_51.jpg,480,640,laptop,279,178,404,282\n","laptop_52.jpg,424,640,laptop,78,117,376,402\n","laptop_53.jpg,426,640,laptop,220,174,377,319\n","laptop_53.jpg,426,640,laptop,349,181,446,281\n","laptop_54.jpg,478,640,laptop,85,248,410,334\n","laptop_54.jpg,478,640,laptop,23,275,151,294\n","laptop_55.jpg,480,640,laptop,182,169,404,391\n","laptop_56.jpg,640,427,laptop,134,295,196,335\n","laptop_57.jpg,480,640,laptop,88,2,636,412\n","laptop_58.jpg,640,479,laptop,20,439,316,580\n","laptop_59.jpg,375,500,laptop,212,118,347,248\n","laptop_60.jpg,640,480,laptop,99,308,189,418\n","laptop_61.jpg,480,640,laptop,18,0,397,388\n","laptop_62.jpg,424,640,laptop,2,26,631,417\n","laptop_63.jpg,335,500,laptop,284,0,417,69\n","laptop_64.jpg,480,640,laptop,221,259,285,297\n","laptop_65.jpg,640,480,laptop,162,359,254,439\n","laptop_66.jpg,480,640,laptop,254,138,442,329\n","laptop_67.jpg,480,640,laptop,355,297,445,382\n","laptop_67.jpg,480,640,laptop,153,327,397,434\n","laptop_68.jpg,480,640,laptop,201,0,638,473\n","laptop_69.jpg,480,640,laptop,155,213,242,322\n","laptop_69.jpg,480,640,laptop,59,193,139,260\n","laptop_69.jpg,480,640,laptop,522,246,639,361\n","laptop_69.jpg,480,640,laptop,333,218,420,269\n","laptop_69.jpg,480,640,laptop,231,260,474,456\n","laptop_70.jpg,480,640,laptop,517,199,639,314\n","laptop_71.jpg,425,640,laptop,225,2,639,401\n","laptop_72.jpg,478,640,laptop,300,17,637,471\n","laptop_73.jpg,640,480,laptop,8,126,258,344\n","laptop_74.jpg,640,532,laptop,394,506,471,546\n","laptop_75.jpg,428,640,laptop,126,60,572,419\n","laptop_75.jpg,428,640,laptop,157,16,357,225\n","laptop_76.jpg,480,640,laptop,0,7,271,62\n","laptop_77.jpg,431,640,laptop,343,218,481,343\n","laptop_78.jpg,320,640,laptop,483,177,618,273\n","laptop_78.jpg,320,640,laptop,347,119,389,139\n","laptop_79.jpg,425,640,laptop,289,0,635,289\n","laptop_80.jpg,375,500,laptop,317,0,499,101\n","laptop_81.jpg,375,500,laptop,148,272,213,356\n","laptop_82.jpg,480,640,laptop,28,214,108,228\n","laptop_83.jpg,640,425,laptop,196,369,310,453\n","laptop_84.jpg,289,500,laptop,203,7,393,223\n","laptop_85.jpg,480,640,laptop,355,365,553,470\n","laptop_86.jpg,480,640,laptop,33,140,251,391\n","laptop_87.jpg,427,640,laptop,5,162,191,201\n","laptop_88.jpg,480,640,laptop,537,92,639,236\n","laptop_89.jpg,480,640,laptop,98,153,524,473\n","laptop_90.jpg,480,640,laptop,288,215,593,470\n","laptop_90.jpg,480,640,laptop,221,169,406,385\n","laptop_91.jpg,333,500,laptop,373,270,489,330\n","laptop_91.jpg,333,500,laptop,383,245,444,280\n","laptop_92.jpg,427,640,laptop,254,123,432,215\n","laptop_93.jpg,480,640,laptop,184,228,639,471\n","laptop_94.jpg,480,640,laptop,481,197,639,272\n","laptop_94.jpg,480,640,laptop,43,291,237,388\n","laptop_95.jpg,480,640,laptop,241,51,536,359\n","laptop_96.jpg,426,640,laptop,72,252,263,425\n","laptop_97.jpg,427,640,laptop,31,194,224,370\n","laptop_98.jpg,427,640,laptop,380,305,571,367\n","laptop_99.jpg,457,640,laptop,137,229,186,257\n","laptop_99.jpg,457,640,laptop,240,221,289,254\n","laptop_99.jpg,457,640,laptop,531,221,567,250\n","laptop_99.jpg,457,640,laptop,38,254,74,258\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MzVqg60NTwbn","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591517774288,"user_tz":-120,"elapsed":4612,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"2767cb1e-0ddc-4f73-e4e1-84b93af283ad"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Ub2sqbpTxEn","colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"status":"ok","timestamp":1591517781578,"user_tz":-120,"elapsed":7079,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"770de737-4a4e-4d64-f7e4-06ea60a8665e"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 204M\n","drwx------  2 303230 5000 4.0K Jan  4  2019 .\n","drwxr-xr-x 63 root   root 4.0K Jun  7 08:16 ..\n","-rw-------  1 303230 5000  93M Jan  4  2019 model.ckpt.data-00000-of-00001\n","-rw-------  1 303230 5000  68K Jan  4  2019 model.ckpt.index\n","-rw-------  1 303230 5000  20M Jan  4  2019 model.ckpt.meta\n","-rw-------  1 303230 5000 4.3K Jan  4  2019 pipeline.config\n","-rw-------  1 303230 5000  24M Jan  4  2019 tflite_graph.pb\n","-rw-------  1 303230 5000  68M Jan  4  2019 tflite_graph.pbtxt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pDav5JI5Ty1H","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591517781590,"user_tz":-120,"elapsed":1401,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"c29c2ad9-447c-4bff-97b6-87459945540a"},"source":["fine_tune_checkpoint = \"/content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\"\n","fine_tune_checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Embedded_project/Training/model.ckpt-100000'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"65Ac5j75T087"},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nib-9zWZT3iV"},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ol-jp6KOT5Tf"},"source":["import re\n","\n","# training pipeline file defines:\n","# - pretrain model path\n","# - the train/test sets\n","# - ID to Label mapping and number of classes\n","# - training batch size\n","# - epochs to trains\n","# - learning rate\n","# - etc\n","\n","# note we just need to use a sample one, and make edits to it.\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint: downloaded pre-trained model checkpoint path\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test, we created earlier with our training/test sets\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path: ID to label file\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps (Number of epochs to train)\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbvBNodaT8Ci","colab":{"base_uri":"https://localhost:8080/","height":267},"executionInfo":{"status":"ok","timestamp":1591517649243,"user_tz":-120,"elapsed":3424,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"2e9c15f5-6ddf-4e9e-9688-6660a4f0a117"},"source":["%cd /content/EP_JKS/dataset/labels\n","!cat /content/label_map.pbtxt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/EP_JKS/dataset/labels\n","item {\n","    id: 1\n","    name: 'bottle'\n","}\n","\n","item {\n","    id: 2\n","    name: 'bin'\n","}\n","\n","item {\n","    id: 3\n","    name: 'laptop'\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J_6dS4o0T9r6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591517796471,"user_tz":-120,"elapsed":4418,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"744e8c6d-d92a-4ba9-9bb4-b9da2e81dd49"},"source":["# look for num_classes: 6, since we have 5 different road signs and 1 person type (total of 6 types) \n","!cat {pipeline_fname}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# Quantized trained SSD with Mobilenet v2 on MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 3\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 12\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 1000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/My\\ Drive/Embedded_project/Training/train.record\"\n","  }\n","  label_map_path: \"/content/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/My\\ Drive/Embedded_project/Training/test.record\"\n","  }\n","  label_map_path: \"/content/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n","\n","graph_rewriter {\n","  quantization {\n","    delay: 48000\n","    weight_bits: 8\n","    activation_bits: 8\n","  }\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RloMUarwT_h3","colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"status":"ok","timestamp":1591517804921,"user_tz":-120,"elapsed":11845,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"c9c29143-d7c7-4ab4-f913-26ba1430c6dc"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-06-07 08:16:38--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 52.54.251.217, 54.85.41.146, 3.95.144.123, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|52.54.251.217|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  6.48MB/s    in 2.0s    \n","\n","2020-06-07 08:16:41 (6.48 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aX9xLPuYUEsP"},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir \"{}\" --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QCzn9e8IUGsU"},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DR4Bu7jsUIBz","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1591517807306,"user_tz":-120,"elapsed":7575,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"47a969d4-0748-4868-d8c1-6ec22a9d5ea3"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","IndexError: list index out of range\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f_zT87bWUJ_J"},"source":["num_steps = 100000\n","!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir='{model_dir}' \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-U7yVsVTDDsb","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"ok","timestamp":1591517812295,"user_tz":-120,"elapsed":4964,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"56b58972-ad99-4f04-8b71-4dea9ebcac68"},"source":["!ls -ltra '{model_dir}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 1789219\n","-rw------- 1 root root 1141685397 Jun  6 15:18 train.record\n","-rw------- 1 root root   25719978 Jun  6 15:21 test.record\n","drwx------ 2 root root       4096 Jun  6 15:40 eval_0\n","-rw------- 1 root root   59305312 Jun  6 15:47 events.out.tfevents.1591457349.ff82d92a8549\n","drwx------ 3 root root       4096 Jun  6 15:47 fine_tuned_model\n","-rw------- 1 root root   59306427 Jun  6 15:52 events.out.tfevents.1591458591.ff82d92a8549\n","-rw------- 1 root root   31332964 Jun  6 17:12 graph.pbtxt\n","drwx------ 2 root root       4096 Jun  6 21:41 .ipynb_checkpoints\n","-rw------- 1 root root      68664 Jun  7 03:12 model.ckpt-94616.index\n","-rw------- 1 root root   74452352 Jun  7 03:12 model.ckpt-94616.data-00000-of-00001\n","-rw------- 1 root root   16444948 Jun  7 03:12 model.ckpt-94616.meta\n","-rw------- 1 root root      68664 Jun  7 03:22 model.ckpt-96076.index\n","-rw------- 1 root root   74452352 Jun  7 03:22 model.ckpt-96076.data-00000-of-00001\n","-rw------- 1 root root   16444948 Jun  7 03:22 model.ckpt-96076.meta\n","-rw------- 1 root root      68664 Jun  7 03:32 model.ckpt-97534.index\n","-rw------- 1 root root   74452352 Jun  7 03:32 model.ckpt-97534.data-00000-of-00001\n","-rw------- 1 root root   16444948 Jun  7 03:32 model.ckpt-97534.meta\n","-rw------- 1 root root      68664 Jun  7 03:42 model.ckpt-98991.index\n","-rw------- 1 root root   74452352 Jun  7 03:42 model.ckpt-98991.data-00000-of-00001\n","-rw------- 1 root root   16444948 Jun  7 03:42 model.ckpt-98991.meta\n","-rw------- 1 root root      68664 Jun  7 03:50 model.ckpt-100000.index\n","-rw------- 1 root root   74452352 Jun  7 03:50 model.ckpt-100000.data-00000-of-00001\n","-rw------- 1 root root   16444948 Jun  7 03:50 model.ckpt-100000.meta\n","-rw------- 1 root root        279 Jun  7 03:50 checkpoint\n","drwx------ 3 root root       4096 Jun  7 03:50 export\n","-rw------- 1 root root   59955738 Jun  7 03:50 events.out.tfevents.1591463530.92a387f1ab2e\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1SnjPgnCDIvA"},"source":["import os\n","import re\n","import numpy as np\n","\n","output_directory = '%s/fine_tuned_model' % model_dir\n","os.makedirs(output_directory, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XenD1Y5wDL6g","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591517826756,"user_tz":-120,"elapsed":1066,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"c2cbef05-76c8-4ce8-ed9b-bc4670f9fac3"},"source":["lst = os.listdir(model_dir)\n","# find the last model checkpoint file, i.e. model.ckpt-1000.meta\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_agnGuvADQLq","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591517877454,"user_tz":-120,"elapsed":49174,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"ea283b0c-d95a-4de6-97d2-993a3173547d"},"source":["!echo creates the frozen inference graph in fine_tune_model\n","# there is an \"Incomplete shape\" message.  but we can safely ignore that. \n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory='{output_directory}' \\\n","    --trained_checkpoint_prefix='{last_model_path}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["creates the frozen inference graph in fine_tune_model\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0607 08:17:15.560713 140515778631552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:17:17.456127 140515778631552 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:17:17.579927 140515778631552 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:17:17.613504 140515778631552 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:17:17.647502 140515778631552 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:17:17.687778 140515778631552 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:17:17.720422 140515778631552 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0607 08:17:17.948922 140515778631552 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0607 08:17:18.296173 140515778631552 deprecation.py:323] From /content/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0607 08:17:19.588406 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0607 08:17:19.588708 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0607 08:17:19.588959 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0607 08:17:19.589139 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0607 08:17:19.589375 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0607 08:17:19.589539 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0607 08:17:19.589792 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0607 08:17:19.589992 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0607 08:17:19.590228 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0607 08:17:19.590395 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0607 08:17:19.590645 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0607 08:17:19.590816 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0607 08:17:19.591048 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0607 08:17:19.591212 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0607 08:17:19.591437 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0607 08:17:19.591619 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0607 08:17:19.591881 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0607 08:17:19.592049 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0607 08:17:19.592278 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0607 08:17:19.592445 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0607 08:17:19.592711 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0607 08:17:19.592887 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0607 08:17:19.593133 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0607 08:17:19.593312 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0607 08:17:19.593539 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0607 08:17:19.593719 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0607 08:17:19.593946 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0607 08:17:19.594117 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0607 08:17:19.594381 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0607 08:17:19.594583 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0607 08:17:19.594879 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0607 08:17:19.595056 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0607 08:17:19.595333 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0607 08:17:19.595523 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0607 08:17:19.595797 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0607 08:17:19.595971 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0607 08:17:19.596140 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0607 08:17:19.596297 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0607 08:17:19.596461 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0607 08:17:19.596632 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0607 08:17:19.596796 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0607 08:17:19.596955 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0607 08:17:19.597120 140515778631552 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0607 08:17:19.599186 140515778631552 deprecation.py:323] From /content/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0607 08:17:19.600049 140515778631552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","257 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.61m params)\n","  BoxPredictor_0 (--/13.85k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/6.92k params)\n","      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","  BoxPredictor_1 (--/61.49k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/30.74k params)\n","      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","  BoxPredictor_2 (--/24.62k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/12.31k params)\n","      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","  BoxPredictor_3 (--/12.34k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/6.17k params)\n","      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","  BoxPredictor_4 (--/12.34k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/6.17k params)\n","      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","  BoxPredictor_5 (--/6.19k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/3.10k params)\n","      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","257 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/4.49m flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n","  FeatureExtractor/MobilenetV2/Conv_1/mul_fold (409.60k/409.60k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/mul_fold (327.68k/327.68k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/project/mul_fold (307.20k/307.20k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/project/mul_fold (92.16k/92.16k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/project/mul_fold (36.86k/36.86k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/project/mul_fold (12.29k/12.29k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/project/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/project/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/project/mul_fold (2.30k/2.30k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/expand/mul_fold (1.54k/1.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/mul_fold (1.30k/1.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/mul_fold (1.30k/1.30k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  FeatureExtractor/MobilenetV2/Conv/mul_fold (864/864 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/mul_fold (864/864 flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/project/mul_fold (512/512 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/depthwise/mul_fold (288/288 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","\n","======================End of Report==========================\n","2020-06-07 08:17:22.168460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-07 08:17:22.181350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.181923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:17:22.182186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:17:22.183220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:17:22.184282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:17:22.184631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:17:22.186057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:17:22.187412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:17:22.191080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:17:22.191184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.191769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.192276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:17:22.192572: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-06-07 08:17:22.197337: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-06-07 08:17:22.197605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29f4680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:17:22.197632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-07 08:17:22.288500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.289175: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29f4a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:17:22.289208: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-06-07 08:17:22.289364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.289902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:17:22.289988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:17:22.290009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:17:22.290039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:17:22.290050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:17:22.290061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:17:22.290077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:17:22.290094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:17:22.290164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.290714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.291199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:17:22.291258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:17:22.292431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-07 08:17:22.292456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-06-07 08:17:22.292463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-06-07 08:17:22.292573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.293150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:22.293639: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-07 08:17:22.293671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\n","I0607 08:17:22.296478 140515778631552 saver.py:1284] Restoring parameters from /content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0607 08:17:52.881259 140515778631552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-06-07 08:17:53.516455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:53.517092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:17:53.517172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:17:53.517195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:17:53.517232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:17:53.517253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:17:53.517279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:17:53.517300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:17:53.517320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:17:53.517425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:53.518191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:53.518708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:17:53.518749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-07 08:17:53.518762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-06-07 08:17:53.518774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-06-07 08:17:53.518862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:53.519507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:53.520048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\n","I0607 08:17:53.521849 140515778631552 saver.py:1284] Restoring parameters from /content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0607 08:17:54.493173 140515778631552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0607 08:17:54.493416 140515778631552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 632 variables.\n","I0607 08:17:55.035087 140515778631552 graph_util_impl.py:334] Froze 632 variables.\n","INFO:tensorflow:Converted 632 variables to const ops.\n","I0607 08:17:55.128360 140515778631552 graph_util_impl.py:394] Converted 632 variables to const ops.\n","2020-06-07 08:17:55.323605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:55.324163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:17:55.324244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:17:55.324269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:17:55.324290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:17:55.324312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:17:55.324341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:17:55.324361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:17:55.324380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:17:55.324464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:55.325025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:55.325507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:17:55.325544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-07 08:17:55.325568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-06-07 08:17:55.325578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-06-07 08:17:55.325673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:55.326194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:17:55.326736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0607 08:17:55.958887 140515778631552 deprecation.py:323] From /content/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0607 08:17:55.959579 140515778631552 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0607 08:17:55.959722 140515778631552 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/drive/My Drive/Embedded_project/Training/fine_tuned_model/saved_model/saved_model.pb\n","I0607 08:17:56.280266 140515778631552 builder_impl.py:425] SavedModel written to: /content/drive/My Drive/Embedded_project/Training/fine_tuned_model/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to /content/drive/My Drive/Embedded_project/Training/fine_tuned_model/pipeline.config\n","I0607 08:17:56.311494 140515778631552 config_util.py:225] Writing pipeline config file to /content/drive/My Drive/Embedded_project/Training/fine_tuned_model/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UwfDb2RdDcyP","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591517889491,"user_tz":-120,"elapsed":50387,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"2ded877f-29cb-48db-c262-61e32a684c8f"},"source":["# https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\n","# create the tensorflow lite graph\n","!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --trained_checkpoint_prefix='{last_model_path}' \\\n","    --output_directory='{output_directory}' \\\n","    --add_postprocessing_op=true"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0607 08:18:01.628100 140365109655424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:18:03.608767 140365109655424 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:18:03.636020 140365109655424 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:18:03.662795 140365109655424 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:18:03.689020 140365109655424 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:18:03.716070 140365109655424 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0607 08:18:03.742533 140365109655424 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","2020-06-07 08:18:03.780350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-07 08:18:03.792675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.793192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:18:03.793449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:03.801503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:18:03.802642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:18:03.802938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:18:03.804460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:18:03.805468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:18:03.809063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:18:03.809162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.809716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.810184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:18:03.810434: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-06-07 08:18:03.815522: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-06-07 08:18:03.815787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b8aa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:18:03.815815: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-07 08:18:03.902364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.903182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b8b640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:18:03.903212: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-06-07 08:18:03.903363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.903918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:18:03.903988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:03.904006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:18:03.904016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:18:03.904028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:18:03.904041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:18:03.904053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:18:03.904067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:18:03.904127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.904674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.905150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:18:03.905215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:03.906349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-07 08:18:03.906375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-06-07 08:18:03.906381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-06-07 08:18:03.906481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.907012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:03.907487: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-07 08:18:03.907521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I0607 08:18:05.950410 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I0607 08:18:05.950688 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I0607 08:18:05.950906 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I0607 08:18:05.951050 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I0607 08:18:05.951261 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I0607 08:18:05.951399 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I0607 08:18:05.951614 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I0607 08:18:05.951752 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I0607 08:18:05.951949 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I0607 08:18:05.952106 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I0607 08:18:05.952308 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I0607 08:18:05.952437 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I0607 08:18:05.952644 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I0607 08:18:05.952774 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I0607 08:18:05.952968 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I0607 08:18:05.953101 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I0607 08:18:05.953286 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I0607 08:18:05.953414 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I0607 08:18:05.953622 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I0607 08:18:05.953791 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I0607 08:18:05.954022 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I0607 08:18:05.954177 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I0607 08:18:05.954378 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I0607 08:18:05.954514 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I0607 08:18:05.954730 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I0607 08:18:05.954864 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I0607 08:18:05.955068 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I0607 08:18:05.955202 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I0607 08:18:05.955414 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I0607 08:18:05.955541 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I0607 08:18:05.955769 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I0607 08:18:05.955914 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I0607 08:18:05.956120 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I0607 08:18:05.956246 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I0607 08:18:05.956435 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I0607 08:18:05.956568 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I0607 08:18:05.956691 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I0607 08:18:05.956809 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I0607 08:18:05.956928 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I0607 08:18:05.957051 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I0607 08:18:05.957170 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I0607 08:18:05.957288 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I0607 08:18:05.957406 140365109655424 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0607 08:18:06.394298 140365109655424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-06-07 08:18:07.016442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:07.017026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:18:07.017111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:07.017136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:18:07.017155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:18:07.017175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:18:07.017194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:18:07.017212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:18:07.017241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:18:07.017326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:07.017884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:07.018408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:18:07.018457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-07 08:18:07.018471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-06-07 08:18:07.018480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-06-07 08:18:07.018579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:07.019102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:07.019612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\n","I0607 08:18:07.021314 140365109655424 saver.py:1284] Restoring parameters from /content/drive/My Drive/Embedded_project/Training/model.ckpt-100000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0607 08:18:07.902362 140365109655424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0607 08:18:07.902607 140365109655424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 632 variables.\n","I0607 08:18:08.381164 140365109655424 graph_util_impl.py:334] Froze 632 variables.\n","INFO:tensorflow:Converted 632 variables to const ops.\n","I0607 08:18:08.454281 140365109655424 graph_util_impl.py:394] Converted 632 variables to const ops.\n","2020-06-07 08:18:08.575921: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"93owVJ26DmS1","colab":{"base_uri":"https://localhost:8080/","height":787},"executionInfo":{"status":"ok","timestamp":1591517897901,"user_tz":-120,"elapsed":54894,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"b7d232db-d900-4acb-9cb0-261f077c933c"},"source":["!echo \"CONVERTING frozen graph to quantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/custom_object_detection.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --inference_type=QUANTIZED_UINT8 \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CONVERTING frozen graph to quantized TF Lite file...\n","2020-06-07 08:18:14.983498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-07 08:18:14.996134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:14.996705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:18:14.996950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:14.998023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:18:14.999046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:18:14.999336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:18:15.000751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:18:15.001837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:18:15.005214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:18:15.005312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.005878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.006360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:18:15.006669: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-06-07 08:18:15.011281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-06-07 08:18:15.011527: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a3abc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:18:15.011584: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-07 08:18:15.097149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.097807: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a3ad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:18:15.097848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-06-07 08:18:15.097988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.098491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:18:15.098529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:15.098544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:18:15.098588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:18:15.098602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:18:15.098613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:18:15.098624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:18:15.098637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:18:15.098687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.099193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.099695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:18:15.099752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:15.100717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-07 08:18:15.100740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-06-07 08:18:15.100746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-06-07 08:18:15.100842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.101349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:15.101849: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-07 08:18:15.101880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X3sCzEAsDtV3","colab":{"base_uri":"https://localhost:8080/","height":787},"executionInfo":{"status":"ok","timestamp":1591517906289,"user_tz":-120,"elapsed":59178,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"eed62f3b-2022-4930-ac2e-ab650a4360fe"},"source":["!echo \"CONVERTING frozen graph to unquantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/Coo.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CONVERTING frozen graph to unquantized TF Lite file...\n","2020-06-07 08:18:23.085408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-07 08:18:23.097760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.098309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:18:23.098536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:23.099697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:18:23.100735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:18:23.101023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:18:23.102376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:18:23.103432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:18:23.106700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:18:23.106785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.107311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.107793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:18:23.108080: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-06-07 08:18:23.112836: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-06-07 08:18:23.113102: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27c4a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:18:23.113135: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-07 08:18:23.197726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.198465: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27c4bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-07 08:18:23.198494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-06-07 08:18:23.198668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.199177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-06-07 08:18:23.199220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:23.199234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-06-07 08:18:23.199243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-06-07 08:18:23.199254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-06-07 08:18:23.199265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-06-07 08:18:23.199276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-06-07 08:18:23.199288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-07 08:18:23.199332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.199853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.200327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-06-07 08:18:23.200375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-06-07 08:18:23.201318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-07 08:18:23.201344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-06-07 08:18:23.201355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-06-07 08:18:23.201448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.202006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-07 08:18:23.202543: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-07 08:18:23.202597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"siXcvWaWDvRQ","colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"status":"ok","timestamp":1591517911330,"user_tz":-120,"elapsed":56814,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"e2f60178-0f20-4e58-946f-f1eaf51accb9"},"source":["print(output_directory)\n","!ls -ltra '{output_directory}'\n","#pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\") # this is main one\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")  # this is tflite graph\n","!cp '{label_map_pbtxt_fname}' '{output_directory}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Embedded_project/Training/fine_tuned_model\n","total 133541\n","-rw------- 1 root root  2159785 Jun  7 08:17 model.ckpt.meta\n","-rw------- 1 root root    23537 Jun  7 08:17 model.ckpt.index\n","-rw------- 1 root root 18726392 Jun  7 08:17 model.ckpt.data-00000-of-00001\n","-rw------- 1 root root       77 Jun  7 08:17 checkpoint\n","-rw------- 1 root root 19570272 Jun  7 08:17 frozen_inference_graph.pb\n","drwx------ 3 root root     4096 Jun  7 08:17 saved_model\n","-rw------- 1 root root     4192 Jun  7 08:17 pipeline.config\n","-rw------- 1 root root 19211873 Jun  7 08:18 tflite_graph.pb\n","-rw------- 1 root root 53702629 Jun  7 08:18 tflite_graph.pbtxt\n","-rw------- 1 root root  4743944 Jun  7 08:18 custom_object_detection.tflite\n","-rw------- 1 root root 18596280 Jun  7 08:18 Coo.tflite\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mrHjak9Y3YDI"},"source":["import os, os.path, shutil\n","\n","folder_path = \"/content/dataset/test/images\"\n","\n","images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n","\n","for image in images:\n","    folder_name = image.split('.')[0]\n","\n","    new_path = os.path.join(folder_path, folder_name)\n","    if not os.path.exists(new_path):\n","        os.makedirs(new_path)\n","\n","    old_image_path = os.path.join(folder_path, image)\n","    new_image_path = os.path.join(new_path, image)\n","    shutil.move(old_image_path, new_image_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTlpx7fmD1UF","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1591519192556,"user_tz":-120,"elapsed":1228,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"5cef7916-da61-4eca-959e-4f0c556cb3dd"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","print(PATH_TO_CKPT)\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  \"/content/test_images/4L/4L\"\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Embedded_project/Training/fine_tuned_model/frozen_inference_graph.pb\n","['/content/test_images/4L/4L/laptop_69.jpg', '/content/test_images/4L/4L/laptop_57.jpg', '/content/test_images/4L/4L/laptop_73.jpg', '/content/test_images/4L/4L/laptop_86.jpg', '/content/test_images/4L/4L/laptop_84.jpg', '/content/test_images/4L/4L/laptop_82.jpg', '/content/test_images/4L/4L/laptop_85.jpg', '/content/test_images/4L/4L/laptop_87.jpg', '/content/test_images/4L/4L/laptop_78.jpg', '/content/test_images/4L/4L/laptop_59.jpg', '/content/test_images/4L/4L/laptop_72.jpg', '/content/test_images/4L/4L/laptop_66.jpg', '/content/test_images/4L/4L/laptop_77.jpg', '/content/test_images/4L/4L/laptop_62.jpg', '/content/test_images/4L/4L/laptop_79.jpg', '/content/test_images/4L/4L/laptop_70.jpg', '/content/test_images/4L/4L/laptop_65.jpg', '/content/test_images/4L/4L/laptop_61.jpg', '/content/test_images/4L/4L/laptop_58.jpg', '/content/test_images/4L/4L/laptop_68.jpg', '/content/test_images/4L/4L/laptop_75.jpg', '/content/test_images/4L/4L/laptop_56.jpg', '/content/test_images/4L/4L/laptop_81.jpg', '/content/test_images/4L/4L/laptop_71.jpg', '/content/test_images/4L/4L/laptop_80.jpg', '/content/test_images/4L/4L/laptop_74.jpg', '/content/test_images/4L/4L/laptop_60.jpg', '/content/test_images/4L/4L/laptop_63.jpg', '/content/test_images/4L/4L/laptop_76.jpg', '/content/test_images/4L/4L/laptop_83.jpg', '/content/test_images/4L/4L/laptop_64.jpg', '/content/test_images/4L/4L/laptop_67.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NUBPOnyjEOeG","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591519197045,"user_tz":-120,"elapsed":1730,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"2868f8e8-409c-4890-f05a-f7bc02dbd91d"},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G94rSD_VEXl-"},"source":["%matplotlib inline\n","\n","print('Running inferences on %s' % TEST_IMAGE_PATHS)\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=2)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJyDDExG9lau"},"source":["### Webcam Video Input\n","\n","Use this command to run object detection with the model and video streaming from your computer's camera:\n","\n","```\n","python3 detect_camera.py \\\n","  --model models/mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite \\\n","  --labels models/coco_labels.txt \\\n","  --output images/processed.avi\n","```\n","\n","The video output with detection plays on screen, and saves to `images/processed.avi`. Omit the `--output` argument to not save the video.\n","\n","To compare the performance when not using the Edge TPU, try\n","running it again with the model that's *not* compiled for the Edge TPU:\n","\n","```\n","python3 detect_camera.py \\\n","  --model models/mobilenet_ssd_v2_coco_quant_postprocess.tflite \\\n","  --labels models/coco_labels.txt \\\n","  --output images/processed.avi\n","```\n","\n","You will need to install open-cv to run this example:\n","\n","```\n","pip3 install opencv-python\n","```\n"," 117  python/examples/detection/detect_camera.py \n","Viewed\n","@@ -0,0 +1,117 @@\n","\"\"\"Example using TF Lite to detect objects in a laptop camera.\"\"\"\n","\n","\n","import argparse\n","import cv2\n","import time\n","import numpy as np\n","\n","from PIL import Image\n","from PIL import ImageDraw\n","\n","import detect\n","from detect_image import load_labels, make_interpreter, draw_objects\n","import tflite_runtime.interpreter as tflite\n","\n","EDGETPU_SHARED_LIB = 'libedgetpu.so.1'\n","\n","def draw_objects_and_info(draw, objs, labels, info):\n","  draw_objects(draw, objs, labels)\n","  draw.text((0,0), info, fill='green')\n","\n","class MovingAvgPerf():\n","  def __init__(self, nticks=10):\n","    self.times = []\n","    self.nticks = nticks\n","\n","  def tick(self, diff):\n","    self.times.append(diff)\n","    if len(self.times) > self.nticks:\n","      self.times.pop(0)\n","\n","  def fps_str(self):\n","    fps = len(self.times) / sum(self.times)\n","    return '%.2f fps' % fps\n","\n","class MovingWindowPerf(MovingAvgPerf):\n","\n","  def tick(self):\n","    super().tick(time.monotonic())\n","\n","  def fps_str(self):\n","    if len(self.times) == 1:\n","      fps = 0\n","    else:\n","      fps = len(self.times) / (self.times[-1] - self.times[0])\n","    return '%.2f fps' % fps\n","\n","\n","def main():\n","  parser = argparse.ArgumentParser(\n","      formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n","  parser.add_argument('-m', '--model', required=True,\n","                      help='File path of .tflite file.')\n","  parser.add_argument('-l', '--labels',\n","                      help='File path of labels file.')\n","  parser.add_argument('-t', '--threshold', type=float, default=0.4,\n","                      help='Score threshold for detected objects.')\n","  parser.add_argument('-o', '--output',\n","                      help='File path for the result video with annotations (eg: images/processed.avi)')\n","  args = parser.parse_args()\n","\n","  labels = load_labels(args.labels) if args.labels else {}\n","  interpreter = make_interpreter(args.model)\n","  interpreter.allocate_tensors()\n","\n","  video_capture = cv2.VideoCapture(0)\n","  video_out = None\n","\n","  perf = MovingWindowPerf()\n","  tpuperf = MovingAvgPerf()\n","  print('Running... Press q to quit.')\n","  while True:\n","    # Capture frame-by-frame\n","    ret, frame = video_capture.read()\n","\n","    # Crop the central square of the video feed\n","    height, width, _ = frame.shape   # Get dimensions\n","    new_width = min(width, height)\n","    new_height = new_width\n","\n","    left = int( (width - new_width)/2 )\n","    top = int( (height - new_height)/2 )\n","    right = int( (width + new_width)/2 )\n","    bottom = int( (height + new_height)/2 )\n","\n","    image = Image.fromarray(frame[top:bottom,left:right])\n","    if video_out is None and args.output:\n","      video_out = cv2.VideoWriter(args.output, cv2.VideoWriter_fourcc('M','J','P','G'), 17, (new_width,new_height))\n","\n","    # Inference\n","    scale = detect.set_input(interpreter, image.size,\n","                             lambda size: image.resize(size, Image.ANTIALIAS))\n","    start = time.monotonic()\n","    interpreter.invoke()\n","    tpuperf.tick(time.monotonic() - start)\n","    perf.tick()\n","    objs = detect.get_output(interpreter, args.threshold, scale)\n","\n","    # Display the resulting frame\n","    msg = '%s\\n%s tpu rate' % (perf.fps_str(), tpuperf.fps_str())\n","    draw_objects_and_info(ImageDraw.Draw(image), objs, labels, msg)\n","    cv2.imshow('Video', np.asarray(image))\n","\n","    if video_out is not None:\n","      video_out.write(np.asarray(image))\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","      break\n","\n","  # When everything is done, release the capture\n","  if video_out is not None:\n","    video_out.release()\n","  video_capture.release()\n","  cv2.destroyAllWindows()\n","\n","if __na"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXXp7Kh--qC-","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591519983980,"user_tz":-120,"elapsed":3715,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"341831bc-ab26-45da-8ae9-aaa35b397037"},"source":["!git clone https://github.com/ilyakava/tflite.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'tflite' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0thjxcns-2wl","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591521067686,"user_tz":-120,"elapsed":1218,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"5f11e727-1c62-42f2-dcb1-84b3ae148e64"},"source":["cd /content/video"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/video\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rcNnvbos_fK8","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1591521072502,"user_tz":-120,"elapsed":3700,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"663d02ec-8ce4-4c13-d75f-ad626fdafa83"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/video\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3f0UMQaH_t4l","colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"status":"ok","timestamp":1591522307913,"user_tz":-120,"elapsed":3812,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"2fa15ecb-4574-4f76-c008-87963b558fa6"},"source":["!python detect_video.py --model custom_object_detection_edgetpu.tflite --labels /content/video/label_map.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] parsing class labels...\n","[INFO] loading Coral model...\n","Traceback (most recent call last):\n","  File \"detect_video.py\", line 38, in <module>\n","    model = DetectionEngine(args[\"model\"])\n","  File \"/usr/lib/python3/dist-packages/edgetpu/detection/engine.py\", line 73, in __init__\n","    super().__init__(model_path)\n","  File \"/usr/lib/python3/dist-packages/edgetpu/basic/basic_engine.py\", line 92, in __init__\n","    self._engine = BasicEnginePythonWrapper.CreateFromFile(model_path)\n","RuntimeError: No Edge TPU device detected!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K5p4raMJEDxH"},"source":["!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n","\n","!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n","\n","!sudo apt-get update\n","\n","!sudo apt-get install edgetpu-compiler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLlgdGhuET1g"},"source":["!edgetpu_compiler /content/drive/My\\ Drive/Embedded_project/Training/fine_tuned_model/custom_object_detection.tflite"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQUfJA4pFQuv","colab":{"base_uri":"https://localhost:8080/","height":870},"executionInfo":{"status":"ok","timestamp":1591521665256,"user_tz":-120,"elapsed":13538,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"4fa6702d-2385-4f8e-8689-61f7854cff91"},"source":["!sudo apt-get update\n","\n","!sudo apt-get install python3-edgetpu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rHit:1 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease\n","\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [1 InRelease gpgv 6,332 B] [Connecting to archive.ubuntu.com] [Connecting to\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Co\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Co\r0% [Release.gpg gpgv 697 B] [Connecting to archive.ubuntu.com (91.189.88.142)] \r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","\r0% [Release.gpg gpgv 697 B] [Waiting for headers] [Waiting for headers] [Connec\r0% [Waiting for headers] [Waiting for headers] [Connecting to cloud.r-project.o\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [Connec\r                                                                               \rHit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [Connec\r                                                                               \rHit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Connecting to cloud.r-projec\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connecting to ppa\r0% [7 InRelease gpgv 21.3 kB] [Waiting for headers] [Connecting to cloud.r-proj\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connecting to ppa\r0% [8 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rHit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [8 InRelease gpgv 88.7 kB] [Connecting to cloud.r-project.org] [Connecting t\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connecting to ppa\r0% [10 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to cloud.r-proj\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Waiting for heade\r                                                                               \rHit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n","Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Get:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n","Fetched 3,626 B in 1s (2,573 B/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  python3-olefile python3-pil\n","Suggested packages:\n","  python-pil-doc python3-pil-dbg\n","The following NEW packages will be installed:\n","  python3-edgetpu python3-olefile python3-pil\n","0 upgraded, 3 newly installed, 0 to remove and 64 not upgraded.\n","Need to get 2,774 kB of archives.\n","After this operation, 10.1 MB of additional disk space will be used.\n","Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 python3-edgetpu amd64 14.0 [2,412 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-pil amd64 5.1.0-1ubuntu0.2 [329 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-olefile all 0.45.1-1 [33.3 kB]\n","Fetched 2,774 kB in 2s (1,348 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python3-pil:amd64.\n","(Reading database ... 144877 files and directories currently installed.)\n","Preparing to unpack .../python3-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n","Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Selecting previously unselected package python3-edgetpu.\n","Preparing to unpack .../python3-edgetpu_14.0_amd64.deb ...\n","Unpacking python3-edgetpu (14.0) ...\n","Selecting previously unselected package python3-olefile.\n","Preparing to unpack .../python3-olefile_0.45.1-1_all.deb ...\n","Unpacking python3-olefile (0.45.1-1) ...\n","Setting up python3-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python3-olefile (0.45.1-1) ...\n","Setting up python3-edgetpu (14.0) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uNrq0CZyJH6k","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"error","timestamp":1591523042548,"user_tz":-120,"elapsed":1271,"user":{"displayName":"manjunath reddy","photoUrl":"","userId":"15913550410447560446"}},"outputId":"b679591d-abae-4191-fc15-1956f95f32d1"},"source":["import cv2\n","from PIL import Image\n","import numpy as np\n","import tensorflow as tf\n","\n","def read_tensor_from_readed_frame(frame, input_height=224, input_width=224,\n","        input_mean=0, input_std=255):\n","  output_name = \"normalized\"\n","  float_caster = tf.cast(frame, tf.float32)\n","  dims_expander = tf.expand_dims(float_caster, 0);\n","  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n","  normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n","  sess = tf.Session()\n","  result = sess.run(normalized)\n","  return result\n","\n","def load_labels(label_file):\n","  label = []\n","  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n","  for l in proto_as_ascii_lines:\n","    label.append(l.rstrip())\n","  return label\n","\n","def VideoSrcInit(paath):\n","    cap = cv2.VideoCapture(paath)\n","    flag, image = cap.read()\n","    if flag:\n","        print(\"Valid Video Path. Lets move to detection!\")\n","    else:\n","        raise ValueError(\"Video Initialization Failed. Please make sure video path is valid.\")\n","    return cap\n","\n","def main():\n","  Labels_Path = \"/content/drive/My Drive/Embedded_project/Training/label_map.txt\"\n","  Model_Path = \"/content/drive/My Drive/Embedded_project/Training/fine_tuned_model/custom_object_detection.tflite\"\n","  input_path = \"/content/WIN_20200607_11_42_36_Pro.mp4\"\n","\n","  ##Loading labels\n","  labels = load_labels(Labels_Path)\n","\n","  ##Load tflite model and allocate tensors\n","  interpreter = tf.lite.Interpreter(model_path=Model_Path)\n","  interpreter.allocate_tensors()\n","  # Get input and output tensors.\n","  input_details = interpreter.get_input_details()\n","  output_details = interpreter.get_output_details()\n","\n","  input_shape = input_details[0]['shape']\n","\n","  ##Read video\n","  cap = VideoSrcInit(input_path)\n","\n","  while True:\n","    ok, cv_image = cap.read()\n","    if not ok:\n","      break\n","\n","    ##Converting the readed frame to RGB as opencv reads frame in BGR\n","    image = Image.fromarray(cv_image).convert('RGB')\n","\n","    ##Converting image into tensor\n","    image_tensor = read_tensor_from_readed_frame(image ,224, 224)\n","\n","    ##Test model\n","    interpreter.set_tensor(input_details[0]['index'], image_tensor)\n","    interpreter.invoke()\n","    output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","    ## You need to check the output of the output_data variable and \n","    ## map it on the frame in order to draw the bounding boxes.\n","\n","\n","    cv2.namedWindow(\"cv_image\", cv2.WINDOW_NORMAL)\n","    cv2.imshow(\"cv_image\",cv_image)\n","\n","    ##Use p to pause the video and use q to termiate the program\n","    key = cv2.waitKey(10) & 0xFF\n","    if key == ord(\"q\"):\n","      break\n","    elif key == ord(\"p\"):\n","      cv2.waitKey(0)\n","      continue \n","  cap.release()\n","\n","if __name__ == '__main__':\n","  main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Valid Video Path. Lets move to detection!\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-101-baf1b6fd1141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-101-baf1b6fd1141>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m##Test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    344\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \"\"\"\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\u001b[0m in \u001b[0;36mSetTensor\u001b[0;34m(self, i, value)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensorflow_wrap_interpreter_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreterWrapper_SetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got tensor of type FLOAT32 but expected type UINT8 for input 260, name: normalized_input_image_tensor "]}]}]}